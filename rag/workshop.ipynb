{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop: From Simple to Agentic RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸŽ‰ Free Pinecone API key\n",
    "\n",
    "Before you run this notebook, head over to this [link to create a free Pinecone Account](https://www.pinecone.io).\n",
    "\n",
    "Alternatively if you have a Pinecone API key feel free to proceed.\n",
    "\n",
    "Next head over to [Tavily](https://app.tavily.com/home) and sign up for a free account and get your API key.\n",
    "\n",
    "We will use [`uv`](https://docs.astral.sh/uv/getting-started/installation/) to install the workshop package and its dependencies.\n",
    "\n",
    "\n",
    "```bash\n",
    "!git clone https://github.com/ash0ts/workshops.git\n",
    "!cd workshops/rag\n",
    "!pip install uv\n",
    "!uv pip install -e .\n",
    "```\n",
    "\n",
    "Create an `.env` file in the workshop/rag directory and add the API keys to it:\n",
    "\n",
    "```.env\n",
    "PINECONE_API_KEY=\"YOUR_COHERE_API_KEY\"\n",
    "TAVILY_API_KEY=\"YOUR_TAVILY_API_KEY\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import wandb\n",
    "import weave\n",
    "from copy import deepcopy\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import convert_contents_to_text, make_id, render_doc, printmd, chunk_simple, chunk_markdown, load_dataset, chunk_dataset\n",
    "from retrieval_metrics import RetrievalScorer\n",
    "from response_metrics import ResponseScorer\n",
    "from retriever import TfidfSearchEngine, BM25SearchEngine, DenseSearchEngine, Retriever, RetrieverWithReranker, HybridRetrieverWithReranker, VectorStoreSearchEngine\n",
    "from generation import SimpleResponseGenerator, QueryEnhancedResponseGenerator\n",
    "from pipeline import SimpleRAGPipeline, QueryEnhancedRAGPipeline\n",
    "from query_enhancer import QueryEnhancer\n",
    "from agent import Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are downloading the finance PDF files we will use as our data source.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weave_client = weave.init(\"rag-workshop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download_finance_docs import PDFProcessor\n",
    "processor = PDFProcessor()\n",
    "data = processor.load_pdf_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_dir = \"../data/finance_docs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_dir = pathlib.Path(docs_dir)\n",
    "docs_files = sorted(docs_dir.rglob(\"*.pdf\"))\n",
    "\n",
    "print(f\"Number of files: {len(docs_files)}\\n\")\n",
    "print(\"First 5 files:\\n{files}\".format(files=\"\\n\".join(map(str, docs_files[:5]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tokens = sum(map(lambda x: x[\"metadata\"][\"raw_tokens\"], data))\n",
    "print(f\"Total Tokens in dataset: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build weave dataset\n",
    "raw_data = weave.Dataset(name=\"raw_data\", rows=data)\n",
    "\n",
    "# publish the dataset\n",
    "weave.publish(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple RAG Pipeline\n",
    "\n",
    "First, we will learn about building a simple RAG pipeline. We will mainly focus on how to preprocess and chunk the data followed by building a simple retrieval engine without using any fancy \"Vector Index\". The idea is to show the inner working of a retrieval pipeline and make you understand the workflow from a user query to a generated response using an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chunks = []\n",
    "docs = raw_data.rows\n",
    "for doc in docs:\n",
    "    chunks = chunk_simple(doc[\"content\"], chunk_size=500)\n",
    "    doc_id = make_id(doc[\"content\"])\n",
    "    for chunk in chunks:\n",
    "        doc_chunk = deepcopy(doc)\n",
    "        doc_chunk[\"chunk\"] = chunk\n",
    "        doc_chunk[\"text\"] = convert_contents_to_text(chunk)\n",
    "        doc_chunk[\"chunk_id\"] = make_id(chunk)\n",
    "        doc_chunk[\"doc_id\"] = doc_id\n",
    "        document_chunks.append(doc_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_search_engine = await TfidfSearchEngine().fit(document_chunks)\n",
    "\n",
    "class TFIDFRetriever(Retriever):\n",
    "    pass\n",
    "\n",
    "tfidf_retriever = TFIDFRetriever(search_engine=tfidf_search_engine)\n",
    "# retrieved_docs = await tfidf_search_engine.search(query=\"How has Apple's revenue from iPhone sales fluctuated across quarters?\", top_k=5)\n",
    "# for doc in retrieved_docs:\n",
    "#     render_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs_data = [{\"document\": item[\"text\"]} for item in retrieved_docs]\n",
    "simple_response_generator = SimpleResponseGenerator()\n",
    "# response = await simple_response_generator.invoke(\n",
    "#     query=\"How has Apple's revenue from iPhone sales fluctuated across quarters?\", documents=docs_data\n",
    "# )\n",
    "# printmd(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDFRAGPipeline(SimpleRAGPipeline):\n",
    "    pass\n",
    "tfidf_rag_pipeline = TFIDFRAGPipeline(\n",
    "    retriever=tfidf_retriever,\n",
    "    generator=simple_response_generator\n",
    ")\n",
    "# response = await tfidf_rag_pipeline.invoke(query=\"How has Apple's revenue from iPhone sales fluctuated across quarters?\",)\n",
    "# printmd(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating the RAG Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluating the Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = weave.ref(\"weave:///a-sh0ts/rag-course-finance/object/eval_data:CoQDvdOENbZqkwg7IlhZm33drBCAf9OUNvf8ar6YHzM\").get()\n",
    "\n",
    "print(\"Number of evaluation samples: \", len(eval_dataset.rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_evaluation = weave.Evaluation(\n",
    "    name=\"Retrieval_Evaluation\",\n",
    "    dataset=eval_dataset,\n",
    "    scorers=[RetrievalScorer(name=\"retrieval_scorer\", description=\"Retrieval metrics\")],\n",
    "    preprocess_model_input=lambda x: {\"query\": x[\"question\"], \"top_k\": 5},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_retrieval_scores = await retrieval_evaluation.evaluate(\n",
    "    model=tfidf_retriever,\n",
    "    __weave={\"display_name\": \"TFIDF Retrieval\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluationg the Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "response_evaluation = weave.Evaluation(\n",
    "    name=\"Response_Evaluation\",\n",
    "    dataset=eval_dataset,\n",
    "    scorers=[ResponseScorer(name=\"response_scorer\", description=\"Response metrics\")],\n",
    "    preprocess_model_input=lambda x: {\"query\": x[\"question\"]},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_response_scores = await response_evaluation.evaluate(\n",
    "    model=tfidf_rag_pipeline,\n",
    "    __weave={\"display_name\": \"TFIDF RAG Pipeline\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_search_engine = await BM25SearchEngine().fit(document_chunks)\n",
    "\n",
    "class BM25Retriever(Retriever):\n",
    "    pass\n",
    "\n",
    "bm25_retriever = BM25Retriever(search_engine=bm25_search_engine)\n",
    "\n",
    "# retrieved_docs = await bm25_retriever.invoke(query=\"How has Apple's revenue from iPhone sales fluctuated across quarters?\", top_k=5)\n",
    "\n",
    "# for doc in retrieved_docs:\n",
    "#     render_doc(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_scores = await retrieval_evaluation.evaluate(\n",
    "    model=bm25_retriever,\n",
    "    __weave={\"display_name\": \"BM25 Retrieval\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BM25RAGPipeline(SimpleRAGPipeline):\n",
    "    pass\n",
    "\n",
    "bm25_rag_pipeline = BM25RAGPipeline(\n",
    "    retriever=bm25_retriever,\n",
    "    generator=simple_response_generator\n",
    ")\n",
    "\n",
    "# response = await bm25_rag_pipeline.invoke(query=\"How has Apple's revenue from iPhone sales fluctuated across quarters?\",)\n",
    "\n",
    "# printmd(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_scores = await response_evaluation.evaluate(\n",
    "    model=bm25_rag_pipeline,\n",
    "    __weave={\"display_name\": \"BM25 RAG Pipeline\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_search_engine = DenseSearchEngine()\n",
    "dense_search_engine = await dense_search_engine.fit(document_chunks)\n",
    "\n",
    "class DenseRetriever(Retriever):\n",
    "    pass\n",
    "\n",
    "dense_retriever = DenseRetriever(search_engine=dense_search_engine)\n",
    "# retrieved_docs = await dense_retriever.invoke(query=\"How has Apple's revenue from iPhone sales fluctuated across quarters?\", top_k=5)\n",
    "# for doc in retrieved_docs:\n",
    "#     render_doc(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_scores = await retrieval_evaluation.evaluate(\n",
    "    model=dense_retriever,\n",
    "    __weave={\"display_name\": \"Dense Retrieval\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseRAGPipeline(SimpleRAGPipeline):\n",
    "    pass\n",
    "\n",
    "dense_rag_pipeline = DenseRAGPipeline(\n",
    "    retriever=dense_retriever,\n",
    "    generator=simple_response_generator\n",
    ")\n",
    "\n",
    "# response = await dense_rag_pipeline.invoke(query=\"How has Apple's revenue from iPhone sales fluctuated across quarters?\",)\n",
    "\n",
    "# printmd(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_scores = await response_evaluation.evaluate(\n",
    "    model=dense_rag_pipeline,\n",
    "    __weave={\"display_name\": \"Dense RAG Pipeline\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DenseRerankedRetriever(RetrieverWithReranker):\n",
    "    pass\n",
    "\n",
    "dense_reranked_retriever = DenseRerankedRetriever(search_engine=dense_search_engine,)\n",
    "\n",
    "# retrieved_docs = await dense_reranked_retriever.invoke(query=\"How has Apple's revenue from iPhone sales fluctuated across quarters?\", top_k=10, top_n=5)\n",
    "\n",
    "# for doc in retrieved_docs:\n",
    "#     render_doc(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_scores = await retrieval_evaluation.evaluate(\n",
    "    model=dense_reranked_retriever,\n",
    "    __weave={\"display_name\": \"Dense Reranked Retrieval\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseRerankedRAGPipeline(SimpleRAGPipeline):\n",
    "    pass\n",
    "\n",
    "dense_reranked_rag_pipeline = DenseRerankedRAGPipeline(\n",
    "    retriever=dense_reranked_retriever,\n",
    "    generator=simple_response_generator\n",
    ")\n",
    "\n",
    "# response = await dense_reranked_rag_pipeline.invoke(query=\"How has Apple's revenue from iPhone sales fluctuated across quarters?\",)\n",
    "\n",
    "# printmd(response[\"answer\"])\n",
    "response_scores = await response_evaluation.evaluate(\n",
    "    model=dense_reranked_rag_pipeline,\n",
    "    __weave={\"display_name\": \"Dense Reranked RAG Pipeline\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_retriever = HybridRetrieverWithReranker(\n",
    "    sparse_search_engine=tfidf_search_engine,\n",
    "    dense_search_engine=dense_search_engine\n",
    ")\n",
    "\n",
    "# retrieved_docs = await hybrid_retriever.invoke(query=\"How has Apple's revenue from iPhone sales fluctuated across quarters?\", top_k=10, top_n=5)\n",
    "\n",
    "# for doc in retrieved_docs:\n",
    "#     render_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_retrieval_scores = await retrieval_evaluation.evaluate(\n",
    "    model=hybrid_retriever,\n",
    "    __weave={\"display_name\": \"Hybrid Retrieval\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridRAGPipeline(SimpleRAGPipeline):\n",
    "    pass\n",
    "\n",
    "hybrid_rag_pipeline = HybridRAGPipeline(\n",
    "    retriever=hybrid_retriever,\n",
    "    generator=simple_response_generator\n",
    ")\n",
    "\n",
    "# response = await hybrid_rag_pipeline.invoke(query=\"How has Apple's revenue from iPhone sales fluctuated across quarters?\",)\n",
    "\n",
    "# printmd(response[\"answer\"])\n",
    "hybrid_response_scores = await response_evaluation.evaluate(\n",
    "    model=hybrid_rag_pipeline,\n",
    "    __weave={\"display_name\": \"Hybrid RAG Pipeline\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structured Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_docs = chunk_markdown(docs[0][\"content\"], chunk_size=500)\n",
    "chunked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chunks = []\n",
    "for doc in docs:\n",
    "    chunks = chunk_markdown(doc[\"content\"], chunk_size=500)\n",
    "    doc_id = make_id(doc[\"content\"])\n",
    "    for chunk in chunks:\n",
    "        doc_chunk = deepcopy(doc)\n",
    "        doc_chunk[\"chunk\"] = chunk\n",
    "        doc_chunk[\"text\"] = convert_contents_to_text(chunk)\n",
    "        doc_chunk[\"chunk_id\"] = make_id(chunk)\n",
    "        doc_chunk[\"doc_id\"] = doc_id\n",
    "        document_chunks.append(doc_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_search_engine = await BM25SearchEngine().fit(document_chunks)\n",
    "dense_search_engine = await DenseSearchEngine().fit(document_chunks)\n",
    "hybrid_retriever = HybridRetrieverWithReranker(\n",
    "    sparse_search_engine=bm25_search_engine,\n",
    "    dense_search_engine=dense_search_engine\n",
    ")\n",
    "\n",
    "# retrieved_docs = await hybrid_retriever.invoke(query=\"How has Apple's revenue from iPhone sales fluctuated across quarters?\", top_k=10, top_n=5)\n",
    "\n",
    "# for doc in retrieved_docs:\n",
    "#     render_doc(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_evaluation = weave.Evaluation(\n",
    "    name=\"Retrieval_Evaluation\",\n",
    "    dataset=eval_dataset,\n",
    "    scorers=[RetrievalScorer(name=\"retrieval_scorer\", description=\"Retrieval metrics\")],\n",
    "    preprocess_model_input=lambda x: {\"query\": x[\"question\"], \"top_k\": 10, \"top_n\": 5},\n",
    ")\n",
    "hybrid_retrieval_scores = await retrieval_evaluation.evaluate(\n",
    "    model=hybrid_retriever,\n",
    "    __weave={\"display_name\": \"Hybrid Retrieval With Structured Chunking\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HybridRAGPipeline(SimpleRAGPipeline):\n",
    "    pass\n",
    "\n",
    "hybrid_rag_pipeline = HybridRAGPipeline(\n",
    "    retriever=hybrid_retriever,\n",
    "    generator=simple_response_generator)\n",
    "\n",
    "# response = await hybrid_rag_pipeline.invoke(query=\"How has Apple's revenue from iPhone sales fluctuated across quarters?\",)\n",
    "\n",
    "# printmd(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_response_scores = await response_evaluation.evaluate(\n",
    "    model=hybrid_rag_pipeline,\n",
    "    __weave={\"display_name\": \"Hybrid RAG Pipeline With Structured Chunking\"}\n",
    ")\n",
    "hybrid_response_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## More data, vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_dataset = load_dataset(docs_root)\n",
    "# chunked_dataset = chunk_dataset(full_dataset, chunk_size=500)\n",
    "# vectorstore_search_engine = VectorStoreSearchEngine()\n",
    "# vectorstore_search_engine = await vectorstore_search_engine.fit(chunked_dataset)\n",
    "vectorstore_search_engine = VectorStoreSearchEngine()\n",
    "vectorstore_search_engine = await vectorstore_search_engine.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = await vectorstore_search_engine.search(\n",
    "#     query=\"How has Apple's revenue from iPhone sales fluctuated across quarters?\",\n",
    "#     top_k=5,\n",
    "#     filters=\"file_type in ('notebook', 'markdown')\")\n",
    "# for doc in results:\n",
    "#     render_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStoreRetriever(RetrieverWithReranker):\n",
    "    pass\n",
    "\n",
    "vectorstore_retriever = VectorStoreRetriever(search_engine=vectorstore_search_engine)\n",
    "\n",
    "# results = await vectorstore_retriever.invoke(query=\"How has Apple's revenue from iPhone sales fluctuated across quarters?\", top_k=10, top_n=5, filters=\"file_type in ('notebook', 'markdown')\")\n",
    "# for doc in results:\n",
    "#     render_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_enhancer = QueryEnhancer()\n",
    "results = await query_enhancer.invoke(\"How has Apple's revenue from iPhone sales fluctuated across quarters?\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_enhanced_rag_pipeline = QueryEnhancedRAGPipeline(\n",
    "    query_enhancer=query_enhancer,\n",
    "    retriever=vectorstore_retriever,\n",
    "    response_generator=QueryEnhancedResponseGenerator()\n",
    ")\n",
    "response = await query_enhanced_rag_pipeline.invoke(\"How has Apple's revenue from iPhone sales fluctuated across quarters?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_enhanced_response_scores = await response_evaluation.evaluate(\n",
    "    model=query_enhanced_rag_pipeline,\n",
    "    __weave={\"display_name\": \"Query Enhanced RAG Pipeline\"}\n",
    ")\n",
    "query_enhanced_response_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agentic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent()\n",
    "\n",
    "query = \"\"\n",
    "answer = await agent.invoke(query)\n",
    "printmd(answer[\"answer\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
